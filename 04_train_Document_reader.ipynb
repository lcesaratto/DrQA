{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedBRNN(nn.Module):\n",
    "    \"\"\"Stacked Bi-directional RNNs.\n",
    "\n",
    "    Differs from standard PyTorch library in that it has the option to save\n",
    "    and concat the hidden states between layers. (i.e. the output hidden size\n",
    "    for each sequence input is num_layers * hidden_size).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers,\n",
    "                 dropout_rate=0, dropout_output=False, rnn_type=nn.LSTM,\n",
    "                 concat_layers=False, padding=False):\n",
    "        super(StackedBRNN, self).__init__()\n",
    "        self.padding = padding\n",
    "        self.dropout_output = dropout_output\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_layers = num_layers\n",
    "        self.concat_layers = concat_layers\n",
    "        self.rnns = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            input_size = input_size if i == 0 else 2 * hidden_size\n",
    "            self.rnns.append(rnn_type(input_size, hidden_size,\n",
    "                                      num_layers=1,\n",
    "                                      bidirectional=True))\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        \"\"\"Encode either padded or non-padded sequences.\n",
    "\n",
    "        Can choose to either handle or ignore variable length sequences.\n",
    "        Always handle padding in eval.\n",
    "\n",
    "        Args:\n",
    "            x: batch * len * hdim\n",
    "            x_mask: batch * len (1 for padding, 0 for true)\n",
    "        Output:\n",
    "            x_encoded: batch * len * hdim_encoded\n",
    "        \"\"\"\n",
    "        if x_mask.data.sum() == 0:\n",
    "            # No padding necessary.\n",
    "            output = self._forward_unpadded(x, x_mask)\n",
    "        elif self.padding or not self.training:\n",
    "            # Pad if we care or if its during eval.\n",
    "            output = self._forward_padded(x, x_mask)\n",
    "        else:\n",
    "            # We don't care.\n",
    "            output = self._forward_unpadded(x, x_mask)\n",
    "\n",
    "        return output.contiguous()\n",
    "\n",
    "    def _forward_unpadded(self, x, x_mask):\n",
    "        \"\"\"Faster encoding that ignores any padding.\"\"\"\n",
    "        # Transpose batch and sequence dims\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        # Encode all layers\n",
    "        outputs = [x]\n",
    "        for i in range(self.num_layers):\n",
    "            rnn_input = outputs[-1]\n",
    "\n",
    "            # Apply dropout to hidden input\n",
    "            if self.dropout_rate > 0:\n",
    "                rnn_input = F.dropout(rnn_input,\n",
    "                                      p=self.dropout_rate,\n",
    "                                      training=self.training)\n",
    "            # Forward\n",
    "            rnn_output = self.rnns[i](rnn_input)[0]\n",
    "            outputs.append(rnn_output)\n",
    "\n",
    "        # Concat hidden layers\n",
    "        if self.concat_layers:\n",
    "            output = torch.cat(outputs[1:], 2)\n",
    "        else:\n",
    "            output = outputs[-1]\n",
    "\n",
    "        # Transpose back\n",
    "        output = output.transpose(0, 1)\n",
    "\n",
    "        # Dropout on output layer\n",
    "        if self.dropout_output and self.dropout_rate > 0:\n",
    "            output = F.dropout(output,\n",
    "                               p=self.dropout_rate,\n",
    "                               training=self.training)\n",
    "        return output\n",
    "\n",
    "    def _forward_padded(self, x, x_mask):\n",
    "        \"\"\"Slower (significantly), but more precise, encoding that handles\n",
    "        padding.\n",
    "        \"\"\"\n",
    "        # Compute sorted sequence lengths\n",
    "        lengths = x_mask.data.eq(0).long().sum(1).squeeze()\n",
    "        _, idx_sort = torch.sort(lengths, dim=0, descending=True)\n",
    "        _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
    "        lengths = list(lengths[idx_sort])\n",
    "\n",
    "        # Sort x\n",
    "        x = x.index_select(0, idx_sort)\n",
    "\n",
    "        # Transpose batch and sequence dims\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        # Pack it up\n",
    "        rnn_input = nn.utils.rnn.pack_padded_sequence(x, lengths)\n",
    "\n",
    "        # Encode all layers\n",
    "        outputs = [rnn_input]\n",
    "        for i in range(self.num_layers):\n",
    "            rnn_input = outputs[-1]\n",
    "\n",
    "            # Apply dropout to input\n",
    "            if self.dropout_rate > 0:\n",
    "                dropout_input = F.dropout(rnn_input.data,\n",
    "                                          p=self.dropout_rate,\n",
    "                                          training=self.training)\n",
    "                rnn_input = nn.utils.rnn.PackedSequence(dropout_input,\n",
    "                                                        rnn_input.batch_sizes)\n",
    "            outputs.append(self.rnns[i](rnn_input)[0])\n",
    "\n",
    "        # Unpack everything\n",
    "        for i, o in enumerate(outputs[1:], 1):\n",
    "            outputs[i] = nn.utils.rnn.pad_packed_sequence(o)[0]\n",
    "\n",
    "        # Concat hidden layers or take final\n",
    "        if self.concat_layers:\n",
    "            output = torch.cat(outputs[1:], 2)\n",
    "        else:\n",
    "            output = outputs[-1]\n",
    "\n",
    "        # Transpose and unsort\n",
    "        output = output.transpose(0, 1)\n",
    "        output = output.index_select(0, idx_unsort)\n",
    "\n",
    "        # Pad up to original batch sequence length\n",
    "        if output.size(1) != x_mask.size(1):\n",
    "            padding = torch.zeros(output.size(0),\n",
    "                                  x_mask.size(1) - output.size(1),\n",
    "                                  output.size(2)).type(output.data.type())\n",
    "            output = torch.cat([output, padding], 1)\n",
    "\n",
    "        # Dropout on output layer\n",
    "        if self.dropout_output and self.dropout_rate > 0:\n",
    "            output = F.dropout(output,\n",
    "                               p=self.dropout_rate,\n",
    "                               training=self.training)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqAttnMatch(nn.Module):\n",
    "    \"\"\"Given sequences X and Y, match sequence Y to each element in X.\n",
    "\n",
    "    * o_i = sum(alpha_j * y_j) for i in X\n",
    "    * alpha_j = softmax(y_j * x_i)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, identity=False):\n",
    "        super(SeqAttnMatch, self).__init__()\n",
    "        if not identity:\n",
    "            self.linear = nn.Linear(input_size, input_size)\n",
    "        else:\n",
    "            self.linear = None\n",
    "\n",
    "    def forward(self, x, y, y_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch * len1 * hdim\n",
    "            y: batch * len2 * hdim\n",
    "            y_mask: batch * len2 (1 for padding, 0 for true)\n",
    "        Output:\n",
    "            matched_seq: batch * len1 * hdim\n",
    "        \"\"\"\n",
    "        # Project vectors\n",
    "        if self.linear:\n",
    "            x_proj = self.linear(x.view(-1, x.size(2))).view(x.size())\n",
    "            x_proj = F.relu(x_proj)\n",
    "            y_proj = self.linear(y.view(-1, y.size(2))).view(y.size())\n",
    "            y_proj = F.relu(y_proj)\n",
    "        else:\n",
    "            x_proj = x\n",
    "            y_proj = y\n",
    "\n",
    "        # Compute scores\n",
    "        scores = x_proj.bmm(y_proj.transpose(2, 1))\n",
    "\n",
    "        # Mask padding\n",
    "        y_mask = y_mask.unsqueeze(1).expand(scores.size())\n",
    "        scores.data.masked_fill_(y_mask.data, -float('inf'))\n",
    "\n",
    "        # Normalize with softmax\n",
    "        alpha_flat = F.softmax(scores.view(-1, y.size(1)), dim=-1)\n",
    "        alpha = alpha_flat.view(-1, x.size(1), y.size(1))\n",
    "\n",
    "        # Take weighted average\n",
    "        matched_seq = alpha.bmm(y)\n",
    "        return matched_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearSeqAttn(nn.Module):\n",
    "    \"\"\"A bilinear attention layer over a sequence X w.r.t y:\n",
    "\n",
    "    * o_i = softmax(x_i'Wy) for x_i in X.\n",
    "\n",
    "    Optionally don't normalize output weights.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_size, y_size, identity=False, normalize=True):\n",
    "        super(BilinearSeqAttn, self).__init__()\n",
    "        self.normalize = normalize\n",
    "\n",
    "        # If identity is true, we just use a dot product without transformation.\n",
    "        if not identity:\n",
    "            self.linear = nn.Linear(y_size, x_size)\n",
    "        else:\n",
    "            self.linear = None\n",
    "\n",
    "    def forward(self, x, y, x_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch * len * hdim1\n",
    "            y: batch * hdim2\n",
    "            x_mask: batch * len (1 for padding, 0 for true)\n",
    "        Output:\n",
    "            alpha = batch * len\n",
    "        \"\"\"\n",
    "        Wy = self.linear(y) if self.linear is not None else y\n",
    "        xWy = x.bmm(Wy.unsqueeze(2)).squeeze(2)\n",
    "        xWy.data.masked_fill_(x_mask.data, -float('inf'))\n",
    "        if self.normalize:\n",
    "            if self.training:\n",
    "                # In training we output log-softmax for NLL\n",
    "                alpha = F.log_softmax(xWy, dim=-1)\n",
    "            else:\n",
    "                # ...Otherwise 0-1 probabilities\n",
    "                alpha = F.softmax(xWy, dim=-1)\n",
    "        else:\n",
    "            alpha = xWy.exp()\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSeqAttn(nn.Module):\n",
    "    \"\"\"Self attention over a sequence:\n",
    "\n",
    "    * o_i = softmax(Wx_i) for x_i in X.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearSeqAttn, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch * len * hdim\n",
    "            x_mask: batch * len (1 for padding, 0 for true)\n",
    "        Output:\n",
    "            alpha: batch * len\n",
    "        \"\"\"\n",
    "        x_flat = x.view(-1, x.size(-1))\n",
    "        scores = self.linear(x_flat).view(x.size(0), x.size(1))\n",
    "        scores.data.masked_fill_(x_mask.data, -float('inf'))\n",
    "        alpha = F.softmax(scores, dim=-1)\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnDocReader(nn.Module):\n",
    "    def __init__(self, vocab_size, num_features, embedding_dim=300, normalize=True):\n",
    "        super(RnnDocReader, self).__init__()\n",
    "        # Word embeddings (+1 for padding)\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                      padding_idx=0)\n",
    "\n",
    "        # Projection for attention weighted question\n",
    "        self.qemb_match = SeqAttnMatch(embedding_dim)\n",
    "\n",
    "        # Input size to RNN: word emb + question emb + manual features\n",
    "        doc_input_size = embedding_dim * 2+ num_features\n",
    "\n",
    "        # RNN document encoder\n",
    "        self.doc_rnn = StackedBRNN(\n",
    "            input_size=doc_input_size,\n",
    "            hidden_size=128,\n",
    "            num_layers=3, # Number of encoding layers for document\n",
    "            dropout_rate=0.4,\n",
    "            dropout_output=True,\n",
    "            concat_layers=True,\n",
    "            rnn_type=nn.LSTM,\n",
    "            padding=False, # Explicitly account for padding in RNN encoding\n",
    "        )\n",
    "\n",
    "        # RNN question encoder\n",
    "        self.question_rnn = StackedBRNN(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=128,\n",
    "            num_layers=3,\n",
    "            dropout_rate=0.4,\n",
    "            dropout_output=True,\n",
    "            concat_layers=True,\n",
    "            rnn_type=nn.LSTM,\n",
    "            padding=False,\n",
    "        )\n",
    "\n",
    "        # Output sizes of rnn encoders\n",
    "        doc_hidden_size = 2 * 128 # 2 layers, 128 neurons\n",
    "        question_hidden_size = 2 * 128\n",
    "        # if concatenate rnn layers:\n",
    "        doc_hidden_size *= 3\n",
    "        question_hidden_size *= 3\n",
    "\n",
    "        # Question merging\n",
    "        self.self_attn = LinearSeqAttn(question_hidden_size)\n",
    "\n",
    "        # Bilinear attention for span start/end\n",
    "        self.start_attn = BilinearSeqAttn(\n",
    "            doc_hidden_size,\n",
    "            question_hidden_size,\n",
    "            normalize=normalize,\n",
    "        )\n",
    "        self.end_attn = BilinearSeqAttn(\n",
    "            doc_hidden_size,\n",
    "            question_hidden_size,\n",
    "            normalize=normalize,\n",
    "        )\n",
    "    \n",
    "    def _weighted_avg(self, x, weights):\n",
    "        \"\"\"Return a weighted average of x (a sequence of vectors).\n",
    "\n",
    "        Args:\n",
    "            x: batch * len * hdim\n",
    "            weights: batch * len, sum(dim = 1) = 1\n",
    "        Output:\n",
    "            x_avg: batch * hdim\n",
    "        \"\"\"\n",
    "        return weights.unsqueeze(1).bmm(x).squeeze(1)\n",
    "\n",
    "    def forward(self, x1, x1_f, x1_mask, x2, x2_mask, dropout_emb=0.3):\n",
    "        \"\"\"Inputs:\n",
    "        x1 = document word indices             [batch * len_d]\n",
    "        x1_f = document word features indices  [batch * len_d * nfeat]\n",
    "        x1_mask = document padding mask        [batch * len_d]\n",
    "        x2 = question word indices             [batch * len_q]\n",
    "        x2_mask = question padding mask        [batch * len_q]\n",
    "        \"\"\"\n",
    "        # Embed both document and question\n",
    "        x1_emb = self.embedding(x1)\n",
    "        x2_emb = self.embedding(x2)\n",
    "\n",
    "        # Dropout on embeddings\n",
    "        if dropout_emb > 0:\n",
    "            x1_emb = nn.functional.dropout(x1_emb, p=dropout_emb,\n",
    "                                           training=self.training)\n",
    "            x2_emb = nn.functional.dropout(x2_emb, p=dropout_emb,\n",
    "                                           training=self.training)\n",
    "\n",
    "        # Form document encoding inputs\n",
    "        drnn_input = [x1_emb]\n",
    "\n",
    "        # Add attention-weighted question representation\n",
    "        x2_weighted_emb = self.qemb_match(x1_emb, x2_emb, x2_mask)\n",
    "        drnn_input.append(x2_weighted_emb)\n",
    "\n",
    "        # Add manual features\n",
    "        drnn_input.append(x1_f)\n",
    "\n",
    "        # Encode document with RNN\n",
    "        doc_hiddens = self.doc_rnn(torch.cat(drnn_input, 2), x1_mask)\n",
    "\n",
    "        # Encode question with RNN + merge hiddens\n",
    "        question_hiddens = self.question_rnn(x2_emb, x2_mask)\n",
    "        q_merge_weights = self.self_attn(question_hiddens, x2_mask)\n",
    "        question_hidden = self._weighted_avg(question_hiddens, q_merge_weights)\n",
    "\n",
    "        # Predict start and end positions\n",
    "        start_scores = self.start_attn(doc_hiddens, question_hidden, x1_mask)\n",
    "        end_scores = self.end_attn(doc_hiddens, question_hidden, x1_mask)\n",
    "        return start_scores, end_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    NULL = '<NULL>'\n",
    "    UNK = '<UNK>'\n",
    "    START = 2\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(token):\n",
    "        return unicodedata.normalize('NFD', token)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.tok2ind = {self.NULL: 0, self.UNK: 1}\n",
    "        self.ind2tok = {0: self.NULL, 1: self.UNK}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tok2ind)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.tok2ind)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        if type(key) == int:\n",
    "            return key in self.ind2tok\n",
    "        elif type(key) == str:\n",
    "            return self.normalize(key) in self.tok2ind\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if type(key) == int:\n",
    "            return self.ind2tok.get(key, self.UNK)\n",
    "        if type(key) == str:\n",
    "            return self.tok2ind.get(self.normalize(key),\n",
    "                                    self.tok2ind.get(self.UNK))\n",
    "\n",
    "    def __setitem__(self, key, item):\n",
    "        if type(key) == int and type(item) == str:\n",
    "            self.ind2tok[key] = item\n",
    "        elif type(key) == str and type(item) == int:\n",
    "            self.tok2ind[key] = item\n",
    "        else:\n",
    "            raise RuntimeError('Invalid (key, item) types.')\n",
    "\n",
    "    def add(self, token):\n",
    "        token = self.normalize(token)\n",
    "        if token not in self.tok2ind:\n",
    "            index = len(self.tok2ind)\n",
    "            self.tok2ind[token] = index\n",
    "            self.ind2tok[index] = token\n",
    "\n",
    "    def tokens(self):\n",
    "        \"\"\"Get dictionary tokens.\n",
    "\n",
    "        Return all the words indexed by this dictionary, except for special\n",
    "        tokens.\n",
    "        \"\"\"\n",
    "        tokens = [k for k in self.tok2ind.keys()\n",
    "                  if k not in {'<NULL>', '<UNK>'}]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReaderDataset(Dataset):\n",
    "\n",
    "    def __init__(self, examples, word_dict, feature_dict, single_answer=False):\n",
    "        self.examples = examples\n",
    "        self.word_dict = word_dict\n",
    "        self.feature_dict = feature_dict\n",
    "        self.single_answer = single_answer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Torchify a single example.\"\"\"\n",
    "        ex = self.examples[index]\n",
    "\n",
    "        # Index words\n",
    "        document = torch.LongTensor([self.word_dict[w] for w in ex['document']])\n",
    "        question = torch.LongTensor([self.word_dict[w] for w in ex['question']])\n",
    "\n",
    "        # Create extra features vector\n",
    "        if len(self.feature_dict) > 0:\n",
    "            features = torch.zeros(len(ex['document']), len(self.feature_dict))\n",
    "        else:\n",
    "            features = None\n",
    "\n",
    "        # f_{exact_match}\n",
    "        q_words_cased = {w for w in ex['question']}\n",
    "        q_words_uncased = {w.lower() for w in ex['question']}\n",
    "        q_lemma = {w for w in ex['qlemma']}\n",
    "        for i in range(len(ex['document'])):\n",
    "            if ex['document'][i] in q_words_cased:\n",
    "                features[i][self.feature_dict['in_question']] = 1.0\n",
    "            if ex['document'][i].lower() in q_words_uncased:\n",
    "                features[i][self.feature_dict['in_question_uncased']] = 1.0\n",
    "            if q_lemma and ex['lemma'][i] in q_lemma:\n",
    "                features[i][self.feature_dict['in_question_lemma']] = 1.0\n",
    "\n",
    "        # f_{token} (POS)\n",
    "        for i, w in enumerate(ex['pos']):\n",
    "            f = 'pos=%s' % w\n",
    "            if f in self.feature_dict:\n",
    "                features[i][self.feature_dict[f]] = 1.0\n",
    "\n",
    "        # f_{token} (NER)\n",
    "        for i, w in enumerate(ex['ner']):\n",
    "            f = 'ner=%s' % w\n",
    "            if f in self.feature_dict:\n",
    "                features[i][self.feature_dict[f]] = 1.0\n",
    "\n",
    "        # f_{token} (TF)\n",
    "        counter = Counter([w.lower() for w in ex['document']])\n",
    "        l = len(ex['document'])\n",
    "        for i, w in enumerate(ex['document']):\n",
    "            features[i][self.feature_dict['tf']] = counter[w.lower()] * 1.0 / l\n",
    "\n",
    "        # Maybe return without target\n",
    "        if 'answers' not in ex:\n",
    "            return document, features, question, ex['id']\n",
    "\n",
    "        # ...or with target(s) (might still be empty if answers is empty)\n",
    "        if self.single_answer:\n",
    "            assert(len(ex['answers']) > 0)\n",
    "            start = torch.LongTensor(1).fill_(ex['answers'][0][0])\n",
    "            end = torch.LongTensor(1).fill_(ex['answers'][0][1])\n",
    "        else:\n",
    "            start = [a[0] for a in ex['answers']]\n",
    "            end = [a[1] for a in ex['answers']]\n",
    "\n",
    "        return document, features, question, start, end, ex['id']\n",
    "\n",
    "    def lengths(self):\n",
    "        return [(len(ex['document']), len(ex['question']))\n",
    "                for ex in self.examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.device = self._get_device()\n",
    "        self._set_random_seed()\n",
    "    \n",
    "    def _get_device(self, show_info = False):\n",
    "        if torch.cuda.is_available():    \n",
    "            device = torch.device(\"cuda\")\n",
    "\n",
    "            if show_info:\n",
    "                print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "                print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "\n",
    "            if show_info:\n",
    "                print('No GPU available, using the CPU instead.')\n",
    "\n",
    "        return device\n",
    "    \n",
    "    def _set_random_seed(self, seed=1013):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    def _load_data(self, filename, uncased_question=False, uncased_doc=False, skip_no_answer=False):\n",
    "        \"\"\"Load examples from preprocessed file.\n",
    "        One example per line, JSON encoded.\n",
    "        \"\"\"\n",
    "        # Load JSON lines\n",
    "        with open(filename) as f:\n",
    "            examples = [json.loads(line) for line in f]\n",
    "\n",
    "        # Make case insensitive?\n",
    "        if uncased_question or uncased_doc:\n",
    "            for ex in examples:\n",
    "                if uncased_question:\n",
    "                    ex['question'] = [w.lower() for w in ex['question']]\n",
    "                if uncased_doc:\n",
    "                    ex['document'] = [w.lower() for w in ex['document']]\n",
    "\n",
    "        # Skip unparsed (start/end) examples\n",
    "        if skip_no_answer:\n",
    "            examples = [ex for ex in examples if len(ex['answers']) > 0]\n",
    "\n",
    "        return examples\n",
    "    \n",
    "    def _load_text(self, filename):\n",
    "        \"\"\"Load the paragraphs only of a SQuAD dataset. Store as qid -> text.\"\"\"\n",
    "        # Load JSON file\n",
    "        with open(filename) as f:\n",
    "            examples = json.load(f)['data']\n",
    "\n",
    "        texts = {}\n",
    "        for article in examples:\n",
    "            for paragraph in article['paragraphs']:\n",
    "                for qa in paragraph['qas']:\n",
    "                    texts[qa['id']] = paragraph['context']\n",
    "        return texts\n",
    "\n",
    "    def _load_answers(self, filename):\n",
    "        \"\"\"Load the answers only of a SQuAD dataset. Store as qid -> [answers].\"\"\"\n",
    "        # Load JSON file\n",
    "        with open(filename) as f:\n",
    "            examples = json.load(f)['data']\n",
    "\n",
    "        ans = {}\n",
    "        for article in examples:\n",
    "            for paragraph in article['paragraphs']:\n",
    "                for qa in paragraph['qas']:\n",
    "                    ans[qa['id']] = list(map(lambda x: x['text'], qa['answers']))\n",
    "        return ans\n",
    "\n",
    "    def _build_feature_dict(self, examples):\n",
    "        \"\"\"Index features (one hot) from fields in examples and options.\"\"\"\n",
    "        def _insert(feature):\n",
    "            if feature not in feature_dict:\n",
    "                feature_dict[feature] = len(feature_dict)\n",
    "\n",
    "        feature_dict = {}\n",
    "\n",
    "        # Exact match features\n",
    "        _insert('in_question')\n",
    "        _insert('in_question_uncased')\n",
    "        _insert('in_question_lemma')\n",
    "\n",
    "        # Part of speech tag features\n",
    "        for ex in examples:\n",
    "            for w in ex['pos']:\n",
    "                _insert('pos=%s' % w)\n",
    "\n",
    "        # Named entity tag features\n",
    "        for ex in examples:\n",
    "            for w in ex['ner']:\n",
    "                _insert('ner=%s' % w)\n",
    "\n",
    "        # Term frequency feature\n",
    "        _insert('tf')\n",
    "        \n",
    "        return feature_dict\n",
    "\n",
    "    def _build_word_dict(self, examples, embedding_file):\n",
    "        \"\"\"Return a dictionary from question and document words in\n",
    "        provided examples.\n",
    "        \"\"\"\n",
    "        def load_words(examples, embedding_file):\n",
    "            \"\"\"Iterate and index all the words in examples (documents + questions).\"\"\"\n",
    "            def _insert(iterable, valid_words):\n",
    "                for w in iterable:\n",
    "                    w = Dictionary.normalize(w)\n",
    "                    if valid_words and w not in valid_words:\n",
    "                        continue\n",
    "                    words.add(w)\n",
    "            \n",
    "            # Put all the words in embedding_file into a set.\n",
    "            valid_words = set()\n",
    "            with open(embedding_file) as f:\n",
    "                for line in f:\n",
    "                    w = Dictionary.normalize(line.rstrip().split(' ')[0])\n",
    "                    valid_words.add(w)\n",
    "\n",
    "            words = set()\n",
    "            for ex in examples:\n",
    "                _insert(ex['question'], valid_words)\n",
    "                _insert(ex['document'], valid_words)\n",
    "\n",
    "            return words\n",
    "\n",
    "        word_dict = Dictionary()\n",
    "        for w in load_words(examples, embedding_file):\n",
    "            word_dict.add(w)\n",
    "\n",
    "        return word_dict\n",
    "\n",
    "    def _load_embeddings(self, model, word_dict, embedding_file):\n",
    "        \"\"\"Load pretrained embeddings for a given list of words, if they exist.\n",
    "\n",
    "        Args:\n",
    "            words: iterable of tokens. Only those that are indexed in the\n",
    "                dictionary are kept.\n",
    "            embedding_file: path to text file of embeddings, space separated.\n",
    "        \"\"\"\n",
    "        words = {w for w in word_dict.tokens()}\n",
    "        embedding = model.embedding.weight.data\n",
    "\n",
    "        # When normalized, some words are duplicated. (Average the embeddings).\n",
    "        vec_counts = {}\n",
    "        with open(embedding_file) as f:\n",
    "            # Skip first line if of form count/dim.\n",
    "            line = f.readline().rstrip().split(' ')\n",
    "            if len(line) != 2:\n",
    "                f.seek(0)\n",
    "            for line in f:\n",
    "                parsed = line.rstrip().split(' ')\n",
    "                assert(len(parsed) == embedding.size(1) + 1)\n",
    "                w = word_dict.normalize(parsed[0])\n",
    "                if w in words:\n",
    "                    vec = torch.Tensor([float(i) for i in parsed[1:]])\n",
    "                    if w not in vec_counts:\n",
    "                        vec_counts[w] = 1\n",
    "                        embedding[word_dict[w]].copy_(vec)\n",
    "                    else:\n",
    "                        # 'WARN: Duplicate embedding found\n",
    "                        vec_counts[w] = vec_counts[w] + 1\n",
    "                        embedding[word_dict[w]].add_(vec)\n",
    "\n",
    "        for w, c in vec_counts.items():\n",
    "            embedding[word_dict[w]].div_(c)\n",
    "\n",
    "        print('Loaded %d embeddings (%.2f%%)' %\n",
    "                    (len(vec_counts), 100 * len(vec_counts) / len(words)))\n",
    "\n",
    "    def _top_question_words(self, examples, word_dict, tune_partial=1000):\n",
    "        \"\"\"Count and return the most common question words in provided examples.\"\"\"\n",
    "        word_count = Counter()\n",
    "        for ex in examples:\n",
    "            for w in ex['question']:\n",
    "                w = Dictionary.normalize(w)\n",
    "                if w in word_dict:\n",
    "                    word_count.update([w])\n",
    "        return word_count.most_common(tune_partial)\n",
    "\n",
    "    def _tune_embeddings(self, words, model, word_dict):\n",
    "        \"\"\"Unfix the embeddings of a list of words. This is only relevant if\n",
    "        only some of the embeddings are being tuned (tune_partial = N).\n",
    "\n",
    "        Shuffles the N specified words to the front of the dictionary, and saves\n",
    "        the original vectors of the other N + 1:vocab words in a fixed buffer.\n",
    "\n",
    "        Args:\n",
    "            words: iterable of tokens contained in dictionary.\n",
    "        \"\"\"\n",
    "        words = {w for w in words}\n",
    "\n",
    "        # Shuffle words and vectors\n",
    "        embedding = model.embedding.weight.data\n",
    "        for idx, swap_word in enumerate(words, word_dict.START):\n",
    "            # Get current word + embedding for this index\n",
    "            curr_word = word_dict[idx]\n",
    "            curr_emb = embedding[idx].clone()\n",
    "            old_idx = word_dict[swap_word]\n",
    "\n",
    "            # Swap embeddings + dictionary indices\n",
    "            embedding[idx].copy_(embedding[old_idx])\n",
    "            embedding[old_idx].copy_(curr_emb)\n",
    "            word_dict[swap_word] = idx\n",
    "            word_dict[idx] = swap_word\n",
    "            word_dict[curr_word] = old_idx\n",
    "            word_dict[old_idx] = curr_word\n",
    "\n",
    "        # Save the original, fixed embeddings\n",
    "        model.register_buffer(\n",
    "            'fixed_embedding', embedding[idx + 1:].clone()\n",
    "        )\n",
    "\n",
    "    def _init_optimizer(self, model, weight_decay=0):\n",
    "        \"\"\"Initialize an adamax optimizer for the free parameters of the network.\n",
    "        \"\"\"\n",
    "        parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "        optimizer = torch.optim.Adamax(parameters, weight_decay=weight_decay)\n",
    "        \n",
    "        return optimizer\n",
    "\n",
    "    def _batchify(self, batch):\n",
    "        \"\"\"Gather a batch of individual examples into one batch.\"\"\"\n",
    "        NUM_INPUTS = 3\n",
    "        NUM_TARGETS = 2\n",
    "        NUM_EXTRA = 1\n",
    "\n",
    "        ids = [ex[-1] for ex in batch]\n",
    "        docs = [ex[0] for ex in batch]\n",
    "        features = [ex[1] for ex in batch]\n",
    "        questions = [ex[2] for ex in batch]\n",
    "\n",
    "        \n",
    "        # Batch documents and features\n",
    "        max_length = max([d.size(0) for d in docs])\n",
    "        x1 = torch.LongTensor(len(docs), max_length).zero_()\n",
    "        x1_mask = torch.BoolTensor(len(docs), max_length).fill_(1) # ByteTensor\n",
    "        if features[0] is None:\n",
    "            x1_f = None\n",
    "        else:\n",
    "            x1_f = torch.zeros(len(docs), max_length, features[0].size(1))\n",
    "        for i, d in enumerate(docs):\n",
    "            x1[i, :d.size(0)].copy_(d)\n",
    "            x1_mask[i, :d.size(0)].fill_(0)\n",
    "            if x1_f is not None:\n",
    "                x1_f[i, :d.size(0)].copy_(features[i])\n",
    "\n",
    "        # Batch questions\n",
    "        max_length = max([q.size(0) for q in questions])\n",
    "        x2 = torch.LongTensor(len(questions), max_length).zero_()\n",
    "        x2_mask = torch.BoolTensor(len(questions), max_length).fill_(1)\n",
    "        for i, q in enumerate(questions):\n",
    "            x2[i, :q.size(0)].copy_(q)\n",
    "            x2_mask[i, :q.size(0)].fill_(0)\n",
    "\n",
    "        # Maybe return without targets\n",
    "        if len(batch[0]) == NUM_INPUTS + NUM_EXTRA:\n",
    "            return x1, x1_f, x1_mask, x2, x2_mask, ids\n",
    "\n",
    "        elif len(batch[0]) == NUM_INPUTS + NUM_EXTRA + NUM_TARGETS:\n",
    "            # ...Otherwise add targets\n",
    "            if torch.is_tensor(batch[0][3]):\n",
    "                y_s = torch.cat([ex[3] for ex in batch])\n",
    "                y_e = torch.cat([ex[4] for ex in batch])\n",
    "            else:\n",
    "                y_s = [ex[3] for ex in batch]\n",
    "                y_e = [ex[4] for ex in batch]\n",
    "        else:\n",
    "            raise RuntimeError('Incorrect number of inputs per example.')\n",
    "        \n",
    "        return x1, x1_f, x1_mask, x2, x2_mask, y_s, y_e, ids\n",
    "\n",
    "    def _normalize_answer(self, s):\n",
    "        \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "        def remove_articles(text):\n",
    "            return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "        def white_space_fix(text):\n",
    "            return ' '.join(text.split())\n",
    "\n",
    "        def remove_punc(text):\n",
    "            exclude = set(string.punctuation)\n",
    "            return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "        def lower(text):\n",
    "            return text.lower()\n",
    "\n",
    "        return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "    def _exact_match_score(self, prediction, ground_truth):\n",
    "        \"\"\"Check if the prediction is a (soft) exact match with the ground truth.\"\"\"\n",
    "        return self._normalize_answer(prediction) == self._normalize_answer(ground_truth)\n",
    "\n",
    "    def _f1_score(self, prediction, ground_truth):\n",
    "        \"\"\"Compute the geometric mean of precision and recall for answer tokens.\"\"\"\n",
    "        prediction_tokens = self._normalize_answer(prediction).split()\n",
    "        ground_truth_tokens = self._normalize_answer(ground_truth).split()\n",
    "        common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            return 0\n",
    "        precision = 1.0 * num_same / len(prediction_tokens)\n",
    "        recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "    \n",
    "    def _metric_max_over_ground_truths(self, metric_fn, prediction, ground_truths):\n",
    "        \"\"\"Given a prediction and multiple valid answers, return the score of\n",
    "        the best prediction-answer_n pair given a metric function.\n",
    "        \"\"\"\n",
    "        scores_for_ground_truths = []\n",
    "        for ground_truth in ground_truths:\n",
    "            score = metric_fn(prediction, ground_truth)\n",
    "            scores_for_ground_truths.append(score)\n",
    "        return max(scores_for_ground_truths)\n",
    "\n",
    "    def _decode(self, score_s, score_e, top_n=1, max_len=None):\n",
    "        \"\"\"Take argmax of constrained score_s * score_e.\n",
    "\n",
    "        Args:\n",
    "            score_s: independent start predictions\n",
    "            score_e: independent end predictions\n",
    "            top_n: number of top scored pairs to take\n",
    "            max_len: max span length to consider\n",
    "        \"\"\"\n",
    "        pred_s = []\n",
    "        pred_e = []\n",
    "        pred_score = []\n",
    "        max_len = max_len or score_s.size(1)\n",
    "        for i in range(score_s.size(0)):\n",
    "            # Outer product of scores to get full p_s * p_e matrix\n",
    "            scores = torch.ger(score_s[i], score_e[i])\n",
    "\n",
    "            # Zero out negative length and over-length span scores\n",
    "            scores.triu_().tril_(max_len - 1)\n",
    "\n",
    "            # Take argmax or top n\n",
    "            scores = scores.numpy()\n",
    "            scores_flat = scores.flatten()\n",
    "            if top_n == 1:\n",
    "                idx_sort = [np.argmax(scores_flat)]\n",
    "            elif len(scores_flat) < top_n:\n",
    "                idx_sort = np.argsort(-scores_flat)\n",
    "            else:\n",
    "                idx = np.argpartition(-scores_flat, top_n)[0:top_n]\n",
    "                idx_sort = idx[np.argsort(-scores_flat[idx])]\n",
    "            s_idx, e_idx = np.unravel_index(idx_sort, scores.shape)\n",
    "            pred_s.append(s_idx)\n",
    "            pred_e.append(e_idx)\n",
    "            pred_score.append(scores_flat[idx_sort])\n",
    "        return pred_s, pred_e, pred_score\n",
    "    \n",
    "    def _predict(self, model, ex, top_n=1):\n",
    "        \"\"\"Forward a batch of examples only to get predictions.\n",
    "        \"\"\"\n",
    "        # Eval mode\n",
    "        model.eval()\n",
    "\n",
    "        # Transfer to GPU\n",
    "        inputs = [e if e is None else e.to(self.device) for e in ex[:5]]\n",
    "\n",
    "        # Run forward\n",
    "        with torch.no_grad():\n",
    "            score_s, score_e = model(*inputs)\n",
    "\n",
    "        # Decode predictions\n",
    "        score_s = score_s.data.to('cpu')\n",
    "        score_e = score_e.data.to('cpu')\n",
    "\n",
    "        args = (score_s, score_e, top_n, 15)\n",
    "        \n",
    "        return self._decode(*args)\n",
    "\n",
    "    def _validate_official(self, data_loader, model, global_stats,\n",
    "                      offsets, texts, answers):\n",
    "        \"\"\"Run one full official validation. Uses exact spans and same\n",
    "        exact match/F1 score computation as in the SQuAD script.\n",
    "\n",
    "        Extra arguments:\n",
    "            offsets: The character start/end indices for the tokens in each context.\n",
    "            texts: Map of qid --> raw text of examples context (matches offsets).\n",
    "            answers: Map of qid --> list of accepted answers.\n",
    "        \"\"\"\n",
    "        f1 = AverageMeter()\n",
    "        exact_match = AverageMeter()\n",
    "\n",
    "        # Run through examples\n",
    "        examples = 0\n",
    "        for ex in data_loader:\n",
    "            ex_id, batch_size = ex[-1], ex[0].size(0)\n",
    "            pred_s, pred_e, _ = self._predict(model, ex)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                s_offset = offsets[ex_id[i]][pred_s[i][0]][0]\n",
    "                e_offset = offsets[ex_id[i]][pred_e[i][0]][1]\n",
    "                prediction = texts[ex_id[i]][s_offset:e_offset]\n",
    "\n",
    "                # Compute metrics\n",
    "                ground_truths = answers[ex_id[i]]\n",
    "                exact_match.update(self._metric_max_over_ground_truths(\n",
    "                    self._exact_match_score, prediction, ground_truths))\n",
    "                f1.update(self._metric_max_over_ground_truths(\n",
    "                    self._f1_score, prediction, ground_truths))\n",
    "\n",
    "            examples += batch_size\n",
    "\n",
    "        print('dev valid official: Epoch = %d | EM = %.2f | ' %\n",
    "                    (global_stats['epoch'], exact_match.avg * 100) +\n",
    "                    'F1 = %.2f | examples = %d' %\n",
    "                    (f1.avg * 100, examples))\n",
    "\n",
    "        return {'exact_match': exact_match.avg * 100, 'f1': f1.avg * 100}\n",
    "    \n",
    "    def _save(self, model, word_dict, feature_dict, filename):\n",
    "        state_dict = copy.copy(model.state_dict())\n",
    "        if 'fixed_embedding' in state_dict:\n",
    "            state_dict.pop('fixed_embedding')\n",
    "        params = {\n",
    "            'state_dict': state_dict,\n",
    "            'word_dict': word_dict,\n",
    "            'feature_dict': feature_dict,\n",
    "        }\n",
    "        try:\n",
    "            torch.save(params, filename)\n",
    "        except BaseException:\n",
    "            print('WARN: Saving failed... continuing anyway.')\n",
    "\n",
    "    def init_model(self, train_file, dev_file, embedding_file):\n",
    "        train_exs = self._load_data(train_file, skip_no_answer=True)\n",
    "        dev_exs = self._load_data(dev_file)\n",
    "\n",
    "        # Create a feature dict out of the annotations in the data\n",
    "        feature_dict = self._build_feature_dict(train_exs)\n",
    "\n",
    "        # Build a dictionary from the data questions + words (train/dev splits)\n",
    "        word_dict = self._build_word_dict(train_exs + dev_exs, embedding_file)\n",
    "\n",
    "        # Initialize model\n",
    "        vocab_size = len(word_dict)\n",
    "        num_features = len(feature_dict)\n",
    "        model = RnnDocReader(vocab_size, num_features)\n",
    "\n",
    "        # Load pretrained embeddings for words in dictionary\n",
    "        self._load_embeddings(model, word_dict, EMBEDDING_FILE)\n",
    "\n",
    "        # Set up partial tuning of embeddings\n",
    "        top_words = self._top_question_words(train_exs, word_dict)\n",
    "        self._tune_embeddings([w[0] for w in top_words], model, word_dict)\n",
    "\n",
    "        # Set up optimizer\n",
    "        optimizer = self._init_optimizer(model)\n",
    "\n",
    "        # Move model to gpu\n",
    "        model = model.to(self.device)\n",
    "\n",
    "        return train_exs, dev_exs, word_dict, feature_dict, optimizer, model\n",
    "        \n",
    "    def create_dataloaders(self, dev_json_file, train_exs, dev_exs, word_dict, feature_dict):\n",
    "        # If we are doing offician evals then we need to:\n",
    "            # 1) Load the original text to retrieve spans from offsets.\n",
    "            # 2) Load the (multiple) text answers for each question.\n",
    "        dev_texts = self._load_text(dev_json_file)\n",
    "        dev_offsets = {ex['id']: ex['offsets'] for ex in dev_exs}\n",
    "        dev_answers = self._load_answers(dev_json_file)\n",
    "\n",
    "        train_dataset = ReaderDataset(train_exs, word_dict, feature_dict, single_answer=True)\n",
    "        dev_dataset = ReaderDataset(dev_exs, word_dict, feature_dict, single_answer=False)\n",
    "\n",
    "        train_sampler = torch.utils.data.sampler.RandomSampler(train_dataset)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=32,\n",
    "                sampler=train_sampler,\n",
    "                collate_fn=self._batchify,\n",
    "            )\n",
    "\n",
    "        dev_sampler = torch.utils.data.sampler.SequentialSampler(dev_dataset)\n",
    "        dev_loader = torch.utils.data.DataLoader(\n",
    "                dev_dataset,\n",
    "                batch_size=128,\n",
    "                sampler=dev_sampler,\n",
    "                collate_fn=self._batchify,\n",
    "            )\n",
    "\n",
    "        return train_loader, dev_loader, dev_texts, dev_offsets, dev_answers\n",
    "        \n",
    "    def train(self, train_loader, dev_loader, model, optimizer, dev_offsets, dev_texts, dev_answers, num_epochs, model_file, valid_metric):\n",
    "        stats = {'epoch': 0, 'best_valid': 0}\n",
    "        for epoch in range(num_epochs):\n",
    "            stats['epoch'] = epoch\n",
    "\n",
    "            for idx, ex in tqdm(enumerate(train_loader)):\n",
    "                model.train()\n",
    "\n",
    "                # Transfer to GPU\n",
    "                inputs = [e if e is None else e.to(self.device) for e in ex[:5]]\n",
    "                target_s = ex[5].to(self.device)\n",
    "                target_e = ex[6].to(self.device)\n",
    "\n",
    "                # Run forward\n",
    "                score_s, score_e = model(*inputs)\n",
    "\n",
    "                # Compute loss and accuracies\n",
    "                loss = F.nll_loss(score_s, target_s) + F.nll_loss(score_e, target_e)\n",
    "\n",
    "                # Clear gradients and run backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # Clip gradients\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(),10)\n",
    "\n",
    "                # Update parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                # Reset any partially fixed parameters (e.g. rare words)\n",
    "                embedding = model.embedding.weight.data\n",
    "                fixed_embedding = model.fixed_embedding\n",
    "\n",
    "                # Embeddings to fix are the last indices\n",
    "                offset = embedding.size(0) - fixed_embedding.size(0)\n",
    "                if offset >= 0:\n",
    "                    embedding[offset:] = fixed_embedding\n",
    "\n",
    "            print(f\"train: Epoch {stats['epoch']} done.\")\n",
    "\n",
    "            # Validate official\n",
    "            result = self._validate_official(dev_loader, model, stats,\n",
    "                                    dev_offsets, dev_texts, dev_answers)\n",
    "\n",
    "            # Save best valid\n",
    "            if result[valid_metric] > stats['best_valid']:\n",
    "                self._save(model, word_dict, feature_dict, model_file)\n",
    "                stats['best_valid'] = result[valid_metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train DrQA's Document Reader and evaluate on validation dataset after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 91231 embeddings (100.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2709it [13:16,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 0 done.\n",
      "dev valid official: Epoch = 0 | EM = 62.36 | F1 = 72.68 | examples = 10570\n",
      "train: Epoch 1 done.\n",
      "dev valid official: Epoch = 1 | EM = 63.96 | F1 = 73.81 | examples = 10570\n",
      "train: Epoch 2 done.\n",
      "dev valid official: Epoch = 2 | EM = 64.90 | F1 = 74.42 | examples = 10570\n",
      "train: Epoch 3 done.\n",
      "dev valid official: Epoch = 3 | EM = 65.82 | F1 = 75.27 | examples = 10570\n",
      "train: Epoch 4 done.\n",
      "dev valid official: Epoch = 4 | EM = 66.60 | F1 = 75.74 | examples = 10570\n",
      "train: Epoch 5 done.\n",
      "dev valid official: Epoch = 5 | EM = 67.07 | F1 = 76.55 | examples = 10570\n",
      "train: Epoch 6 done.\n",
      "dev valid official: Epoch = 6 | EM = 67.99 | F1 = 77.09 | examples = 10570\n",
      "train: Epoch 7 done.\n",
      "dev valid official: Epoch = 7 | EM = 67.69 | F1 = 77.31 | examples = 10570\n",
      "train: Epoch 8 done.\n",
      "dev valid official: Epoch = 8 | EM = 68.18 | F1 = 77.56 | examples = 10570\n",
      "train: Epoch 9 done.\n",
      "dev valid official: Epoch = 9 | EM = 67.78 | F1 = 77.23 | examples = 10570\n",
      "train: Epoch 10 done.\n",
      "dev valid official: Epoch = 10 | EM = 68.27 | F1 = 77.68 | examples = 10570\n",
      "train: Epoch 11 done.\n",
      "dev valid official: Epoch = 11 | EM = 68.94 | F1 = 78.31 | examples = 10570\n",
      "train: Epoch 12 done.\n",
      "dev valid official: Epoch = 12 | EM = 68.33 | F1 = 77.55 | examples = 10570\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILE = 'data/datasets/SQuAD-v1.1-train-processed-spacy.txt'\n",
    "DEV_FILE = 'data/datasets/SQuAD-v1.1-dev-processed-spacy.txt'\n",
    "DEV_JSON_FILE = 'data/datasets/SQuAD-v1.1-dev.json'\n",
    "EMBEDDING_FILE = 'data/embeddings/glove.840B.300d.txt'\n",
    "NUM_EPOCHS = 13\n",
    "VALID_METRIC = 'f1'\n",
    "MODEL_FILE = 'tmp/drqa-models/document_reader.mdl'\n",
    "\n",
    "model_class = Model()\n",
    "\n",
    "train_exs, dev_exs, word_dict, feature_dict, optimizer, model = model_class.init_model(TRAIN_FILE,\n",
    "                                                                                        DEV_FILE,\n",
    "                                                                                        EMBEDDING_FILE)\n",
    "\n",
    "train_loader, dev_loader, dev_texts, dev_offsets, dev_answers = model_class.create_dataloaders(DEV_JSON_FILE,\n",
    "                                                                                                train_exs,\n",
    "                                                                                                dev_exs,\n",
    "                                                                                                word_dict,\n",
    "                                                                                                feature_dict)\n",
    "\n",
    "model_class.train(train_loader, dev_loader, model, optimizer, dev_offsets, dev_texts, dev_answers,\n",
    "                    NUM_EPOCHS, MODEL_FILE, VALID_METRIC)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93b4b5566743436c947035f528e38c44cc6a06c2ee96d5f0af65aef54b1da49d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
