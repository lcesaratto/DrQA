{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Wikipedia articles and save their corresponding ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets_lisandro/wikipedia.csv\")\n",
    "tfidf_vectorizer = pickle.load(open(\"models_lisandro/2gram_tfidf.pkl\", \"rb\"))\n",
    "\n",
    "docs_sparse = tfidf_vectorizer.transform(df[\"text\"])\n",
    "\n",
    "save_npz(\"datasets_lisandro/docs_sparse.npz\", docs_sparse)\n",
    "\n",
    "ids = df[\"id\"].values\n",
    "\n",
    "np.save(\"datasets_lisandro/wikipedia_ids.npy\", ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 5 most similar documents to a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal testing on Syrian hamsters</td>\n",
       "      <td>Animal testing on Syrian hamsters\\n\\nSyrian ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Domestication of the Syrian hamster</td>\n",
       "      <td>Domestication of the Syrian hamster\\n\\nThe dom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golden hamster</td>\n",
       "      <td>Golden hamster\\n\\nThe golden hamster, or Syria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hamster</td>\n",
       "      <td>Hamster\\n\\nHamsters are rodents belonging to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Hamsters (album)</td>\n",
       "      <td>The Hamsters (album)\\n\\nThe Hamsters (1993) (k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0    Animal testing on Syrian hamsters   \n",
       "1  Domestication of the Syrian hamster   \n",
       "2                       Golden hamster   \n",
       "3                              Hamster   \n",
       "4                 The Hamsters (album)   \n",
       "\n",
       "                                                text  \n",
       "0  Animal testing on Syrian hamsters\\n\\nSyrian ha...  \n",
       "1  Domestication of the Syrian hamster\\n\\nThe dom...  \n",
       "2  Golden hamster\\n\\nThe golden hamster, or Syria...  \n",
       "3  Hamster\\n\\nHamsters are rodents belonging to t...  \n",
       "4  The Hamsters (album)\\n\\nThe Hamsters (1993) (k...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_sparse = load_npz('datasets_lisandro/docs_sparse.npz')\n",
    "tfidf_vectorizer = pickle.load(open(\"models_lisandro/2gram_tfidf.pkl\", \"rb\"))\n",
    "ids = np.load(\"datasets_lisandro/wikipedia_ids.npy\", allow_pickle=True)\n",
    "\n",
    "db_path = \"data/wikipedia/docs.db\"\n",
    "connection = sqlite3.connect(db_path, check_same_thread=False)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "def get_5_most_similar_documents(query):\n",
    "    query_sparse = tfidf_vectorizer.transform([query])\n",
    "\n",
    "    scores = (docs_sparse * query_sparse.transpose()).toarray()\n",
    "\n",
    "    best_indices = np.argpartition(-scores.ravel(),5)[:5]\n",
    "\n",
    "    selected_ids = ids[best_indices]\n",
    "\n",
    "    cursor.execute(\"SELECT id, text FROM documents WHERE id IN \" + str(tuple(selected_ids.tolist())))\n",
    "    data_json = {\"id\": [], \"text\": []}\n",
    "    for r in cursor.fetchall():\n",
    "        data_json[\"id\"].append(r[0]); data_json[\"text\"].append(r[1])\n",
    "\n",
    "    data_df = pd.DataFrame.from_dict(data_json)\n",
    "\n",
    "    del data_json\n",
    "    gc.collect()\n",
    "\n",
    "    return data_df\n",
    "\n",
    "query = \"How long do Hamsters live?\"\n",
    "display(get_5_most_similar_documents(query).head(5))\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93b4b5566743436c947035f528e38c44cc6a06c2ee96d5f0af65aef54b1da49d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
